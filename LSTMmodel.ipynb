{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "LSTMmodel.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prajwal467/CE888-Assignment2/blob/main/LSTMmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCR7B3BgpLrE",
        "outputId": "f466e6c2-ddfe-40ac-d087-5b6690d64197"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gensim\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import nltk as nl\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score,f1_score\n",
        "\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "import tensorflow.python.keras.layers as layers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IC939pIpLrS"
      },
      "source": [
        "path = \"https://github.com/prajwal467/CE888-Assignment2/tree/main/datasets/emotion\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOrz6HAGpLrU"
      },
      "source": [
        "# Function to map words to their respective values \n",
        "def prepare_text(tokens):\n",
        "    text = []\n",
        "    max_len = 0\n",
        "    for sentence in tokens:\n",
        "        line = []\n",
        "        for word in sentence:\n",
        "            try:\n",
        "                line.append(w2v[word])\n",
        "            except exception as e:\n",
        "                print(e)\n",
        "                print(word)\n",
        "                line.append(0)\n",
        "        max_len = max(max_len,len(line))       \n",
        "        text.append(line)\n",
        "    return np.array(text),max_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Yvk74VQpLrW"
      },
      "source": [
        "#Reading datasets\n",
        "data_train = pd.read_csv(\"https://github.com/prajwal467/CE888-Assignment2/blob/main/datasets/emotion/train_text.txt\",sep=\"\\t\")\n",
        "data_test = pd.read_csv(\"https://github.com/prajwal467/CE888-Assignment2/blob/main/datasets/emotion/test_text.txt\",sep=\"\\t\")\n",
        "data_val = pd.read_csv(\"https://github.com/prajwal467/CE888-Assignment2/blob/main/datasets/emotion/val_text.txt\",sep=\"\\t\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0ja5EAOpLrW"
      },
      "source": [
        "train_label = pd.read_csv(\"https://github.com/prajwal467/CE888-Assignment2/blob/main/datasets/emotion/train_labels.txt\",sep=\"\\t\")\n",
        "test_label = pd.read_csv(\"https://github.com/prajwal467/CE888-Assignment2/blob/main/datasets/emotion/test_labels.txt\",sep=\"\\t\")\n",
        "val_label = pd.read_csv(\"https://github.com/prajwal467/CE888-Assignment2/blob/main/datasets/emotion/val_labels.txt\",sep=\"\\t\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPlVOFxxpLrW",
        "outputId": "061a787c-436b-4d60-908c-30a80135f874"
      },
      "source": [
        "data_val.shape,val_label.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2416, 1), (2366, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5Oqs7StpLrX"
      },
      "source": [
        "# Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5SEyAbWpLrY"
      },
      "source": [
        "# Splitting sentences into words\n",
        "\n",
        "train_tokens = [nl.word_tokenize(sentences) for sentences in data_train]\n",
        "test_tokens = [nl.word_tokenize(sentences) for sentences in data_test]\n",
        "val_tokens = [nl.word_tokenize(sentences) for sentences in data_val]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TClMcWbpLrY",
        "outputId": "a9ac703c-c9ff-4cef-c98f-65d208853635"
      },
      "source": [
        "#training word2vec model on complete vocabulary (train + test vocabulary)\n",
        "\n",
        "model = gensim.models.Word2Vec(size=250, min_count=1, workers=-1)\n",
        "model.build_vocab((train_tokens+test_tokens+val_tokens))\n",
        "model.train((train_tokens+test_tokens+val_tokens),total_examples= len(train_tokens+test_tokens+val_tokens),epochs = 2500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXpSYTCRpLrY",
        "outputId": "ece67ee8-9c43-4714-fee3-7f6628bec692"
      },
      "source": [
        "# storing trained values of every word [0:100] --> [1] \n",
        "w2v = dict(zip(model.wv.index2word, np.mean(model.wv.syn0,axis=1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfcDmrFbpLrZ"
      },
      "source": [
        "# Converting strinf to float values and getting max_len for padding\n",
        "X_train,max_len = prepare_text(train_tokens)\n",
        "X_test,max_len = prepare_text(test_tokens)\n",
        "X_val,max_len = prepare_text(val_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXrMvpnEpLrZ"
      },
      "source": [
        "# Padding to ensure dimensions\n",
        "\n",
        "X_train = pad_sequences(X_train,dtype='float32',padding='post',maxlen= max_len)\n",
        "X_test = pad_sequences(X_test,dtype='float32',padding='post',maxlen = max_len )\n",
        "X_val = pad_sequences(X_val,dtype='float32',padding='post',maxlen = max_len )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t459h9GMpLrZ"
      },
      "source": [
        "# converting labels to one-hot-vector and categorical-vector\n",
        "oe_enc = OneHotEncoder()\n",
        "\n",
        "Y_train = oe_enc.fit_transform(np.array(train_label).reshape(-1,1)).toarray()\n",
        "Y_test = oe_enc.fit_transform(np.array(test_label).reshape(-1,1)).toarray()\n",
        "Y_val = oe_enc.fit_transform(np.array(val_label).reshape(-1,1)).toarray()\n",
        "\n",
        "true_label_train = np.argmax(Y_train,axis=1)\n",
        "true_label_test = np.argmax(Y_test,axis=1)\n",
        "true_label_val = np.argmax(Y_val,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1mJX_fTvMgI"
      },
      "source": [
        "# storing true dimensions\n",
        "n_len_train,features = X_train.shape\n",
        "n_len_test,features = X_test.shape\n",
        "n_len_val,features = X_val.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKU59vLfpLra"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB1dD5SqpLra"
      },
      "source": [
        "# defining optimizer and callback\n",
        "optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
        "es = keras.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZXuB8PnpLrb"
      },
      "source": [
        "X_train,X_test = X_train.reshape(n_len_train,features,1),X_test.reshape(n_len_test,features,1)\n",
        "X_val = X_val.reshape(n_len_val,features,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kr1izBRmpLrb"
      },
      "source": [
        "model = Sequential(name=\"LSTM\")\n",
        "model.add(layers.LSTM(16,input_shape=(X_train.shape[1],1),return_sequences=True))\n",
        "model.add(layers.LSTM(56,return_sequences=True,dropout=0.5))\n",
        "model.add(layers.LSTM(128))\n",
        "model.add(layers.Dense(len(np.unique(true_label_train)),activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8QXNoejpLrb"
      },
      "source": [
        "model.compile(optimizer = optimizer,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsjMudAJpLrc"
      },
      "source": [
        "model.fit(X_train,Y_train,validation_data=(X_test,Y_test),callbacks=[es],epochs=50,verbose=1,batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72M63cUCA6Tb"
      },
      "source": [
        "print(\"F1-SCORE\",f1_score(true_label_val,np.argmax(model.predict(X_val),axis=1),average=\"micro\"))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}